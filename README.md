# ğŸš€ Titanic MLOps Pipeline

## ğŸ¯ Objectif

DÃ©velopper et dÃ©ployer une solution MLOps complÃ¨te sur AWS :

- API REST pour les prÃ©dictions
- Instance pour l'entraÃ®nement du modÃ¨le
- Suivi des expÃ©riences avec **MLflow**
- Automatisation complÃ¨te avec :
  - **Terraform / OpenTofu** (infrastructure)
  - **Ansible** (configuration et dÃ©ploiement)
  - **Docker** (containerisation)

---

## ğŸ–¥ï¸ Architecture

```text
         +------------------+
         | Client (curl/UI) |
         +--------+---------+
                  |
                  v
         +--------+---------+         +-----------------------------+
         |   EC2 Instance   |         |        EC2 Instance         |
         |     API REST     | <-----> |   MLflow + Training server  |
         | (FastAPI + Docker)         | (MLflow + scikit-learn)     |
         +--------+---------+         +-----------------------------+
         Port 8000 : /predict              Port 5000 : MLflow UI


```

Instances utilisÃ©es :
titanic-mlops-api : API REST (FastAPI, uvicorn)

mlflow-tracking-training : MLflow server + entraÃ®nement du modÃ¨le

ğŸ”¨ Technologies
AWS EC2 (instances t3.small)

OpenTofu (Terraform)

Ansible

Docker & Docker Compose

FastAPI (API REST)

MLflow (tracking + model registry)

scikit-learn (modÃ¨le de classification Titanic)

Python 3.12

ğŸŒ RÃ©seau
VPC automatiquement provisionnÃ©

Security Groups :

âœ… Port 8000 : accÃ¨s Ã  l'API

âœ… Port 5000 : accÃ¨s Ã  MLflow

âœ… Port 22 : SSH

ğŸ“ Structure du projet

```text

titanic-mlops-pipeline/
â”œâ”€â”€ api/                 # API REST FastAPI
â”œâ”€â”€ training/            # EntraÃ®nement du modÃ¨le ML
â”œâ”€â”€ data/                # Fichier CSV Titanic
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ terraform/       # Provisionnement (OpenTofu)
â”‚   â””â”€â”€ ansible/         # Configuration Ansible
â”œâ”€â”€ docker-compose.yml   # DÃ©ploiement multi-container
â””â”€â”€ README.md            # Documentation

```

ğŸš€ Instructions de dÃ©ploiement

1ï¸âƒ£ Cloner le dÃ©pÃ´t

```text

git clone https://github.com/romca1012/titanic-mlops-pipeline.git
cd titanic-mlops-pipeline

```

2ï¸âƒ£ Lancer le dÃ©ploiement complet
âš ï¸ PrÃ©requis : renseigner les fichiers suivants :

infra/terraform/terraform.tfvars

ClÃ© SSH privÃ©e dans infra/terraform/_credentials/mlops-key.pem

Puis exÃ©cuter :

```text

./launch.sh

```

Ce script fait automatiquement :

âœ… Provisionnement Terraform

âœ… RÃ©cupÃ©ration des IPs

âœ… GÃ©nÃ©ration de inventory.ini pour Ansible

âœ… Configuration des serveurs via Ansible

âœ… DÃ©ploiement des containers Docker

3ï¸âƒ£ AccÃ©der Ã  l'API et Ã  MLflow
API Swagger : http://<IP_API>:8000/docs

MLflow UI : http://<IP_MLFLOW>:5000

4ï¸âƒ£ Tester l'API (exemple curl)

```text

curl -X POST http://<IP_API>:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"Pclass": 3, "Sex": 1, "Age": 22, "Fare": 7.25, "SibSp": 1, "Parch": 0}'

```

5ï¸âƒ£ Connexion SSH (optionnel)

```text

# Connexion Ã  l'instance API
ssh -i infra/terraform/_credentials/mlops-key.pem ubuntu@<IP_API>

# Connexion Ã  l'instance MLflow / training
ssh -i infra/terraform/_credentials/mlops-key.pem ubuntu@<IP_MLFLOW>

```

6ï¸âƒ£ VÃ©rifier les containers (optionnel)

```text

docker ps -a
docker logs titanic-mlops-pipeline-titanic-mlops-api-1
docker logs titanic-mlops-pipeline-mlflow-tracking-1

```

âœ… Ã€ faire manuellement aprÃ¨s dÃ©ploiement
VÃ©rifier lâ€™API sur Swagger : http://<IP_API>:8000/docs

AccÃ©der Ã  MLflow UI : http://<IP_MLFLOW>:5000

Tester la prÃ©diction via Swagger ou curl

ğŸ§  Auteur
Romaric CAPO-CHICHI
Nikina ZINSOU
Lorin KAKAHOUN

